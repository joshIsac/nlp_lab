{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIXuuKnkKKdA",
        "outputId": "152bf0e8-1c5d-440d-a1a0-2d985cea6856"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import requests\n",
        "\n",
        "# Function to load a transformer model\n",
        "def load_transformer_model(model_name=\"gpt2\"):\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        return tokenizer, model\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model '{model_name}': {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(prompt, model, tokenizer, max_length=50, temperature=1.0):\n",
        "    if model is None:\n",
        "        print(\"Error: Model could not be loaded.\")\n",
        "        return \"\"\n",
        "    try:\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "        attention_mask = input_ids.new_ones(input_ids.shape)  # Attention mask for generated text\n",
        "        output = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.9,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "        return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating text: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to simulate web search using requests\n",
        "def simulate_web_search(query):\n",
        "    try:\n",
        "        url = f\"https://www.caranddriver.com/search/?q={query}\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            return f\"**Web Search Results for '{query}'**\\nFound results on Car and Driver. Visit the website for detailed information.\"\n",
        "        else:\n",
        "            return f\"**Web Search Results for '{query}'**\\nFailed to retrieve search results. Please try again later.\"\n",
        "    except Exception as e:\n",
        "        return f\"**Web Search Results for '{query}'**\\nEncountered an error: {str(e)}. Please try again later.\"\n",
        "\n",
        "# Chatbot Loop\n",
        "while True:\n",
        "    # Greeting\n",
        "    print(\"Hi there! Welcome to VehicleBot.com, your friendly car advisor. How can I help you today?\")\n",
        "\n",
        "    # Choose transformer model\n",
        "    model_name = input(\"Enter a transformer model name (e.g., gpt2, bart-base) or press Enter for default (gpt2): \")\n",
        "    tokenizer, model = load_transformer_model(model_name.strip() if model_name else \"gpt2\")\n",
        "\n",
        "    # User browsing cars\n",
        "    user_browsing = input(\"Are you browsing for a new car? (y/n): \")\n",
        "    if user_browsing.lower() == \"y\":\n",
        "\n",
        "        # Car preferences\n",
        "        car_type = input(\"What kind of cars are you interested in? (e.g., sedan, SUV, sports car): \")\n",
        "        budget = input(\"Do you have a budget in mind? (e.g., $15,000, $30,000+): \")\n",
        "        priorities = input(\"Are there any specific features important to you? (e.g., fuel efficiency, passenger space, cargo space, luxury features, performance): \")\n",
        "\n",
        "        # Generate Recommendation Prompt\n",
        "        prompt = f\"Write a short description of a car that fits the following criteria: Car Type: {car_type}, Budget: {budget}, Priorities: {priorities}\"\n",
        "\n",
        "        # Generate Suggestion Text\n",
        "        recommendation = generate_text(prompt, model, tokenizer)\n",
        "\n",
        "        if recommendation:\n",
        "            # Print Recommendation with simulated web search\n",
        "            print(f\"\\n**Here's a suggestion to get you started:**\\n{recommendation}\\n\")\n",
        "            print(simulate_web_search(recommendation))\n",
        "\n",
        "            # Additional model suggestions (optional)\n",
        "            print(\"\\n**Based on your preferences, here are some other models to consider:**\")\n",
        "            # Implement logic to suggest additional models based on user preferences (e.g., using a car database)\n",
        "            print(\"[List of suggested models based on car_type, budget, and priorities]\")\n",
        "        else:\n",
        "            print(\"Failed to generate recommendation. Please try again later.\")\n",
        "\n",
        "    else:\n",
        "        print(\"No worries! If you need help finding a car in the future, feel free to visit VehicleBot.com again.\")\n",
        "\n",
        "    # Ask for another search\n",
        "    another_search = input(\"Would you like to search for another car today? (y/n): \")\n",
        "    if another_search.lower() != \"y\":\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT2iBiOhTMQX",
        "outputId": "51780c23-dc4f-4f7a-a706-8ee9af2d687c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! Welcome to VehicleBot.com, your friendly car advisor. How can I help you today?\n",
            "Enter a transformer model name (e.g., gpt2, bart-base) or press Enter for default (gpt2): gpt 2\n",
            "Error loading model 'gpt 2': Incorrect path_or_model_id: 'gpt 2'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\n",
            "Are you browsing for a new car? (y/n): y\n",
            "What kind of cars are you interested in? (e.g., sedan, SUV, sports car): sedan\n",
            "Do you have a budget in mind? (e.g., $15,000, $30,000+): $15000\n",
            "Are there any specific features important to you? (e.g., fuel efficiency, passenger space, cargo space, luxury features, performance): passenger space\n",
            "Error: Model could not be loaded.\n",
            "Failed to generate recommendation. Please try again later.\n",
            "Would you like to search for another car today? (y/n): y\n",
            "Hi there! Welcome to VehicleBot.com, your friendly car advisor. How can I help you today?\n",
            "Enter a transformer model name (e.g., gpt2, bart-base) or press Enter for default (gpt2): gpt2\n",
            "Error loading model 'gpt2': Unrecognized configuration class <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\n",
            "Model type should be one of BartConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, EncoderDecoderConfig, FSMTConfig, GPTSanJapaneseConfig, LEDConfig, LongT5Config, M2M100Config, MarianConfig, MBartConfig, MT5Config, MvpConfig, NllbMoeConfig, PegasusConfig, PegasusXConfig, PLBartConfig, ProphetNetConfig, SeamlessM4TConfig, SeamlessM4Tv2Config, SwitchTransformersConfig, T5Config, UMT5Config, XLMProphetNetConfig.\n",
            "Are you browsing for a new car? (y/n): y\n",
            "What kind of cars are you interested in? (e.g., sedan, SUV, sports car): mclaren\n",
            "Do you have a budget in mind? (e.g., $15,000, $30,000+): $30000+\n",
            "Are there any specific features important to you? (e.g., fuel efficiency, passenger space, cargo space, luxury features, performance): performance\n",
            "Error: Model could not be loaded.\n",
            "Failed to generate recommendation. Please try again later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jr5rlxNYTjVv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}